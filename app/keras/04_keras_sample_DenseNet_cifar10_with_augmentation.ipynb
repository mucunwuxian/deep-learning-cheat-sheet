{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "follow from Fork Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]    = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                     as     np\n",
    "import matplotlib.pyplot         as     plt\n",
    "import math\n",
    "from keras.layers                import Input, GlobalAveragePooling2D, Concatenate\n",
    "from keras.layers.core           import Dense, Activation, Flatten\n",
    "from keras.layers.normalization  import BatchNormalization\n",
    "from keras.layers.convolutional  import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.models                import Model\n",
    "from keras.datasets              import fashion_mnist\n",
    "from keras.preprocessing.image   import ImageDataGenerator\n",
    "from tensorflow.python.client    import device_lib\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters       import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(object):\n",
    "    '''\n",
    "    \"Densely Connected Convolutional Networks\"\n",
    "    Gao Huang et al.\n",
    "    https://arxiv.org/abs/1608.06993\n",
    "    '''\n",
    "    def __init__(self, input_shape, output_dim, k=32, theta=0.5):\n",
    "        '''\n",
    "        # Arguments\n",
    "            k:     growth rate\n",
    "            theta: compression rate\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.theta = theta\n",
    "\n",
    "        x = Input(shape=input_shape)\n",
    "        h = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n",
    "        h = BatchNormalization()(h)\n",
    "        h = Activation('relu')(h)\n",
    "        h = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(h)\n",
    "        h, n_channel = self._dense_block(h, 64, 6)\n",
    "        h, n_channel = self._transition(h, n_channel)\n",
    "        h, n_channel = self._dense_block(h, n_channel, 12)\n",
    "        h, n_channel = self._transition(h, n_channel)\n",
    "        h, n_channel = self._dense_block(h, n_channel, 24)\n",
    "        h, n_channel = self._transition(h, n_channel)\n",
    "        h, _ = self._dense_block(h, n_channel, 16)\n",
    "        h = GlobalAveragePooling2D()(h)\n",
    "        h = Dense(1000, activation='relu')(h)\n",
    "        y = Dense(output_dim, activation='softmax')(h)\n",
    "        self.model = Model(x, y)\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.model\n",
    "\n",
    "    def _dense_block(self, x, n_channel, nb_blocks):\n",
    "        h = x\n",
    "        for _ in range(nb_blocks):\n",
    "            stream = h\n",
    "            h = BatchNormalization()(h)\n",
    "            h = Activation('relu')(h)\n",
    "            h = Conv2D(128, kernel_size=(1, 1), padding='same')(h)\n",
    "            h = BatchNormalization()(h)\n",
    "            h = Activation('relu')(h)\n",
    "            h = Conv2D(self.k, kernel_size=(3, 3), padding='same')(h)\n",
    "            h = Concatenate()([stream, h])\n",
    "            n_channel += self.k\n",
    "\n",
    "        return h, n_channel\n",
    "\n",
    "    def _transition(self, x, n_channel):\n",
    "        n_channel = int(n_channel * self.theta)\n",
    "        h = BatchNormalization()(x)\n",
    "        h = Activation('relu')(h)\n",
    "        h = Conv2D(n_channel, kernel_size=(1, 1), padding='same')(h)\n",
    "        return AveragePooling2D()(h), n_channel\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    Build model\n",
    "    '''\n",
    "    densenet = DenseNet121((32, 32, 3), 10)\n",
    "    model = densenet()\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# CIFAR-10の読み込み\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('np.shape(X_train) = (%d, %d, %d, %d)' % np.shape(X_train))\n",
    "print('np.shape(y_train) = (%d, %d)' % np.shape(y_train))\n",
    "print('np.shape(X_test)  = (%d, %d, %d, %d)' % np.shape(X_test))\n",
    "print('np.shape(y_test)  = (%d, %d)' % np.shape(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical y ...\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back up by deep copy\n",
    "X_train_org = X_train.copy()\n",
    "y_train_org = y_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class for data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range      = 20,\n",
    "                             width_shift_range   = 0.2,\n",
    "                             height_shift_range  = 0.2,\n",
    "                             zoom_range          = 0.2,\n",
    "                             channel_shift_range = 50,\n",
    "                             horizontal_flip     = True, \n",
    "                             fill_mode           = 'reflect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# exec augmentation\n",
    "aug_num     = 10 # num of augmentation images from one original image \n",
    "watch_num   = 50 # plot aug image num\n",
    "\n",
    "watch_idx   = np.random.permutation(len(X_train_org))[:watch_num]\n",
    "X_train_aug = np.zeros((np.shape(X_train_org) * np.array([aug_num, 1, 1, 1])), dtype='uint8')\n",
    "y_train_aug = np.zeros((np.shape(y_train_org) * np.array([aug_num, 1])),       dtype='float32')\n",
    "aug_i       = 0\n",
    "\n",
    "for img_i in range(len(X_train_org)):\n",
    "\n",
    "    img_tmp      = X_train_org[img_i:(img_i + 1), :, :, :] # (Height, Width, Channels)  -> (1, Height, Width, Channels) \n",
    "    datagen_flow = datagen.flow(img_tmp, batch_size=1) # 1枚しかないので、ミニバッチ数は1\n",
    "    \n",
    "    watch_flg    = (np.sum(img_i == watch_idx) == 1)\n",
    "    \n",
    "    if (watch_flg):\n",
    "        # Python ジェネレーターで9枚生成して、表示する。\n",
    "        plt.figure(figsize=(10, int(2 * math.ceil(aug_num / 6))))\n",
    "        plt.subplot(math.ceil(aug_num / 6), 6, 1)\n",
    "        plt.imshow(img_tmp[0, :, :, :].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        plt.title('y = %d, img_i = %d' % (np.dot(y_train_org[img_i], (np.arange(len(y_train_org[0])) + 1)), img_i))\n",
    "    \n",
    "    for aug_j in range(aug_num):\n",
    "        batches  = next(datagen_flow)  # (NumBatches, Height, Width, Channels) の4次元データを返す。\n",
    "        gen_img  = batches[0].astype(np.uint8)\n",
    "        X_train_aug[aug_i, :, :, :] = gen_img\n",
    "        y_train_aug[aug_i, :]       = y_train_org[img_i:(img_i + 1), :]\n",
    "\n",
    "        if (watch_flg):\n",
    "            plt.subplot(math.ceil(aug_num / 6), 6, aug_j + 2)\n",
    "            plt.imshow(X_train_aug[aug_i, :, :, :])\n",
    "            plt.axis('off')\n",
    "            plt.title('aug_j = %d' % aug_j)\n",
    "\n",
    "        aug_i    = aug_i + 1\n",
    "         \n",
    "    if (watch_flg):\n",
    "        print('----- (img_i == %d, progress:%.2f%%) -----' % (img_i, (img_i / len(X_train_org) * 100)))\n",
    "        plt.show()\n",
    "\n",
    "print('augmentarion finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add augmentation data\n",
    "X_train = np.concatenate([X_train, X_train_aug], axis=0)\n",
    "y_train = np.concatenate([y_train, y_train_aug], axis=0)\n",
    "\n",
    "print('np.shape(X_train) = (%d, %d, %d, %d)' % np.shape(X_train))\n",
    "print('np.shape(y_train) = (%d, %d)'         % np.shape(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/ShangxuanWu/f53f9d2ca9338f4f13b466509cb07947\n",
    "\n",
    "# Function to distort image\n",
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    \n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape   = image.shape\n",
    "    dx      = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy      = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dz      = np.zeros_like(dx)\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    distored_image = map_coordinates(image, indices, order=3, mode='reflect')\n",
    "    return distored_image.reshape(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec augmentation (elastic distortion)\n",
    "aug_num     = 5  # num of augmentation images from one original image \n",
    "watch_num   = 30 # plot aug image num\n",
    "\n",
    "watch_idx   = np.random.permutation(len(X_train_org))[:watch_num]\n",
    "X_train_aug = np.zeros((np.shape(X_train_org) * np.array([aug_num, 1, 1, 1])), dtype='uint8')\n",
    "y_train_aug = np.zeros((np.shape(y_train_org) * np.array([aug_num, 1])),       dtype='float32')\n",
    "aug_i       = 0\n",
    "\n",
    "alpha_ind   = 1.5\n",
    "sigma_ind   = 0.09\n",
    "\n",
    "for img_i in range(len(X_train_org)):\n",
    "\n",
    "    img_tmp      = X_train_org[img_i:(img_i + 1), :, :, :] # (1, Height, Width, Channels) \n",
    "    datagen_flow = datagen.flow(img_tmp, batch_size=1) # batch_size is np.shape(img_tmp)[0]\n",
    "    \n",
    "    watch_flg    = (np.sum(img_i == watch_idx) == 1)\n",
    "    \n",
    "    if (watch_flg):\n",
    "        plt.figure(figsize=(10, int(5 * math.ceil(aug_num / 6))))\n",
    "        plt.subplot(math.ceil(aug_num / 3), 3, 1)\n",
    "        plt.imshow(img_tmp[0, :, :, :].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        plt.title('y = %d, img_i = %d' % (np.dot(y_train_org[img_i], (np.arange(len(y_train_org[0])) + 1)), img_i))\n",
    "    \n",
    "    for aug_j in range(aug_num):\n",
    "        batches  = next(datagen_flow)  # (NumBatches, Height, Width, Channels)\n",
    "        gen_img  = batches[0].astype(np.uint8)\n",
    "        gen_img  = elastic_transform(image=gen_img, alpha=(gen_img.shape[1] * alpha_ind), sigma=(gen_img.shape[1] * sigma_ind))\n",
    "        X_train_aug[aug_i, :, :, :] = gen_img\n",
    "        y_train_aug[aug_i, :]       = y_train_org[img_i:(img_i + 1), :]\n",
    "\n",
    "        if (watch_flg):\n",
    "            plt.subplot(math.ceil(aug_num / 3), 3, aug_j + 2)\n",
    "            plt.imshow(X_train_aug[aug_i, :, :, :])\n",
    "            plt.axis('off')\n",
    "            plt.title('aug_j = %d' % aug_j)\n",
    "\n",
    "        aug_i    = aug_i + 1\n",
    "         \n",
    "    if (watch_flg):\n",
    "        print('----- (img_i == %d, progress:%.2f%%) -----' % (img_i, (img_i / len(X_train_org) * 100)))\n",
    "        plt.show()\n",
    "\n",
    "print('augmentarion finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add augmentation data\n",
    "X_train = np.concatenate([X_train, X_train_aug], axis=0)\n",
    "y_train = np.concatenate([y_train, y_train_aug], axis=0)\n",
    "\n",
    "print('np.shape(X_train) = (%d, %d, %d, %d)' % np.shape(X_train))\n",
    "print('np.shape(y_train) = (%d, %d)'         % np.shape(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile ...\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc scaling parameter ... (※augmentation前のデータで計算した方が良いかも)\n",
    "X_train_mean = np.mean(X_train)\n",
    "X_train_std  = np.std(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling (normalize) ...\n",
    "X_train = (X_train - X_train_mean) / (X_train_std + 1e-20)\n",
    "X_test  = (X_test  - X_train_mean) / (X_train_std + 1e-20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning ... (※メモリ問題が深刻になってきたら、augmentationやりながらのpartial fitに要切替)\n",
    "model.fit(x               = X_train, \n",
    "          y               = y_train, \n",
    "          batch_size      = 16, \n",
    "          epochs          = 50, \n",
    "          verbose         = 1, \n",
    "          validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
